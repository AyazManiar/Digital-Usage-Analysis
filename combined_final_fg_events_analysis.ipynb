{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a613fe",
   "metadata": {},
   "source": [
    "\n",
    "# Combined Analysis â€” `final_fg_events`\n",
    "\n",
    "This notebook merges, refactors and cleans code from your uploaded SIN notebooks.  \n",
    "**What it does (high-level):**\n",
    "- Loads the canonical dataset `/mnt/data/final_fg_events.csv` (the latest `final_fg_events`).\n",
    "- Cleans & preprocesses timestamps and removes ignored/background packages.\n",
    "- Provides reusable utility functions (grouping, plotting helpers, sleep detection, top-N app extraction).\n",
    "- Runs a standard set of analyses & visualizations: average daily usage (with std), weekday totals, hourly peaks, top apps per-person and global, session & idle-gap analysis, hourly heatmap, and sleep detection timeline.\n",
    "- Outputs are reproducible; cells are logically ordered and functions are reused where possible.\n",
    "\n",
    "> NOTE: I intentionally omitted/ignored any ML/DL code that looked incorrect. This notebook focuses on *data cleaning, EDA and visualizations*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports & config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import timedelta\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 160)\n",
    "sns.set(style='whitegrid')\n",
    "DATA_PATH = '/mnt/data/final_fg_events.csv'\n",
    "print('Notebook created. Data path =', DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a59fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load dataset (canonical) ---\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Raw rows:', len(df))\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Preprocessing & canonicalization ---\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    # Normalize column names (common names from your files)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    # Common expected columns: person_id, start_dt, end_dt, event_name or event_package_name, usage_sec\n",
    "    # Try to handle variations\n",
    "    if 'event_package_name' in df.columns and 'event_name' not in df.columns:\n",
    "        df = df.rename(columns={'event_package_name':'event_name'})\n",
    "    if 'start_date' in df.columns and 'start_time' in df.columns and 'start_dt' not in df.columns:\n",
    "        # combine if separated\n",
    "        df['start_dt'] = df['start_date'].astype(str) + ' ' + df['start_time'].astype(str)\n",
    "    if 'end_date' in df.columns and 'end_time' in df.columns and 'end_dt' not in df.columns:\n",
    "        df['end_dt'] = df['end_date'].astype(str) + ' ' + df['end_time'].astype(str)\n",
    "    # Parse datetimes where necessary\n",
    "    for col in ['start_dt','end_dt']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    # If usage_sec missing, compute from timestamps when possible\n",
    "    if 'usage_sec' not in df.columns or df['usage_sec'].isnull().all():\n",
    "        if ('start_dt' in df.columns) and ('end_dt' in df.columns):\n",
    "            df['usage_sec'] = (df['end_dt'] - df['start_dt']).dt.total_seconds()\n",
    "    # Trim whitespace in event_name\n",
    "    if 'event_name' in df.columns:\n",
    "        df['event_name'] = df['event_name'].astype(str).str.strip()\n",
    "    # Ensure person_id numeric\n",
    "    if 'person_id' in df.columns:\n",
    "        df['person_id'] = pd.to_numeric(df['person_id'], errors='coerce').astype('Int64')\n",
    "    # Drop rows without start_dt or usage_sec\n",
    "    df = df[~df['start_dt'].isna()].copy()\n",
    "    df = df[~df['usage_sec'].isna()].copy()\n",
    "    # Remove negative or zero durations\n",
    "    df = df[df['usage_sec'] > 0].copy()\n",
    "    # Derive useful cols\n",
    "    df['date'] = df['start_dt'].dt.date\n",
    "    df['hour'] = df['start_dt'].dt.hour\n",
    "    df['weekday'] = df['start_dt'].dt.day_name()\n",
    "    return df\n",
    "\n",
    "df = preprocess(df)\n",
    "print('After preprocess rows:', len(df))\n",
    "df[['person_id','start_dt','end_dt','event_name','usage_sec']].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Consolidated ignore list (system & background packages from your notebooks) ---\n",
    "IGNORE_PACKAGES = [\n",
    "    'android','dummy','device_locked_package','com.sarthak.usagetracker',\n",
    "    # common OEM/system packages\n",
    "    'com.android.launcher3','com.oppo.launcher','com.miui.home','com.coloros.alarmclock',\n",
    "    'com.google.android.gms','com.google.android.packageinstaller','com.android.settings',\n",
    "    'com.android.systemui','com.android.dialer','com.android.contacts','com.android.bluetooth',\n",
    "    'com.vivo.globalsearch','com.vivo.hiboard','com.vivo.appstore','com.sec.android.app.launcher',\n",
    "    'com.oplus.camera','com.heytap.browser','com.oppo.quicksearchbox',\n",
    "    # placeholders / known noisy\n",
    "    'com.sophos.networkagent','com.daemon.shelper','com.lbe.security.miui'\n",
    "]\n",
    "# Remove ignored packages if column exists\n",
    "if 'event_name' in df.columns:\n",
    "    initial = len(df)\n",
    "    df = df[~df['event_name'].isin(IGNORE_PACKAGES)].copy()\n",
    "    print('Dropped', initial - len(df), 'ignored-package rows. Remaining:', len(df))\n",
    "else:\n",
    "    print('event_name not found, skipping package filter.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Reusable utility functions ---\n",
    "\n",
    "def group_usage(df, by, seconds_to='min'):\n",
    "    '''Group by columns in `by` and return usage aggregated. seconds_to='min'|'hours'|'sec' '''\n",
    "    temp = df.groupby(by)['usage_sec'].sum().reset_index()\n",
    "    if seconds_to == 'min':\n",
    "        temp['usage_min'] = temp['usage_sec'] / 60\n",
    "    elif seconds_to == 'hours':\n",
    "        temp['usage_hr'] = temp['usage_sec'] / 3600\n",
    "    return temp\n",
    "\n",
    "def top_n_apps(df, n=5, person_id=None):\n",
    "    '''Return top-n apps by usage. If person_id given, filter first.'''\n",
    "    sub = df if person_id is None else df[df['person_id']==person_id]\n",
    "    out = sub.groupby('event_name')['usage_sec'].sum().reset_index().sort_values('usage_sec', ascending=False).head(n)\n",
    "    out['usage_min'] = out['usage_sec']/60\n",
    "    return out\n",
    "\n",
    "def avg_daily_per_person(df):\n",
    "    daily = group_usage(df, ['person_id','date'], seconds_to='sec')\n",
    "    summary = daily.groupby('person_id')['usage_sec'].agg(['mean','std']).reset_index().rename(columns={'mean':'avg_daily_sec','std':'std_daily_sec'})\n",
    "    summary['avg_daily_min'] = summary['avg_daily_sec']/60\n",
    "    summary['std_daily_min'] = summary['std_daily_sec']/60\n",
    "    return summary\n",
    "\n",
    "def peak_hours(df):\n",
    "    hour = group_usage(df, ['hour'], seconds_to='sec')\n",
    "    hour = hour.sort_values('usage_sec', ascending=False)\n",
    "    return hour\n",
    "\n",
    "def detect_sleep_periods(df, min_sleep_hours=3, ignore_small_min=45):\n",
    "    '''\n",
    "    Detect long inactivity gaps per person that likely represent sleep.\n",
    "    Returns DataFrame with person_id, date (based on night), sleep_time (end of last use), wake_time (next start), gap.\n",
    "    '''\n",
    "    data = df.sort_values(['person_id','start_dt']).copy()\n",
    "    data['next_start'] = data.groupby('person_id')['start_dt'].shift(-1)\n",
    "    data['gap'] = data['next_start'] - data['end_dt']\n",
    "    MIN_SLEEP = pd.Timedelta(hours=min_sleep_hours)\n",
    "    IGNORE_SMALL = pd.Timedelta(minutes=ignore_small_min)\n",
    "    data['is_sleep_candidate'] = (data['gap'] >= MIN_SLEEP) & (data['end_dt'].dt.hour.isin(list(range(19,24))+list(range(0,5))))\n",
    "    # pick largest gap per person-date (date anchored to end_dt date)\n",
    "    data['date'] = data['end_dt'].dt.date\n",
    "    sleep_df = data[data['is_sleep_candidate']].sort_values(['person_id','date','gap'], ascending=[True,True,False])\n",
    "    sleep_df = sleep_df.groupby(['person_id','date']).head(1).reset_index(drop=True)\n",
    "    # rename columns\n",
    "    sleep_df = sleep_df.rename(columns={'end_dt':'sleep_time','next_start':'wake_time'})\n",
    "    # calculate durations\n",
    "    sleep_df['sleep_duration'] = sleep_df['wake_time'] - sleep_df['sleep_time']\n",
    "    # filter typical wake before afternoon\n",
    "    sleep_df = sleep_df[sleep_df['wake_time'].dt.hour <= 15]\n",
    "    return sleep_df[['person_id','date','sleep_time','wake_time','sleep_duration','gap']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5de705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Core analyses & visualizations (re-usable flow) ---\n",
    "\n",
    "# 1) Average daily per person (with std)\n",
    "summary = avg_daily_per_person(df)\n",
    "summary = summary.sort_values('avg_daily_min', ascending=False).reset_index(drop=True)\n",
    "display(summary.head(10))\n",
    "\n",
    "# Matplotlib bar (avg daily minutes with std)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(summary['person_id'].astype(str), summary['avg_daily_min'], yerr=summary['std_daily_min'], capsize=4)\n",
    "plt.xlabel('Person ID'); plt.ylabel('Avg Daily Usage (minutes)'); plt.title('Average Daily Screen Time per Person (with std)')\n",
    "plt.show()\n",
    "\n",
    "# 2) Weekday totals (global)\n",
    "weekday_totals = group_usage(df, ['weekday'], seconds_to='min')\n",
    "# Order weekdays\n",
    "weekday_order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "weekday_totals['weekday'] = pd.Categorical(weekday_totals['weekday'], categories=weekday_order, ordered=True)\n",
    "weekday_totals = weekday_totals.sort_values('weekday')\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=weekday_totals, x='weekday', y='usage_min', palette='magma')\n",
    "plt.xticks(rotation=45); plt.ylabel('Total Usage (minutes)'); plt.title('Total Screen Time by Weekday (All Users)')\n",
    "plt.show()\n",
    "\n",
    "# 3) Hourly pattern (global)\n",
    "hourly = group_usage(df, ['hour'], seconds_to='min')\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.lineplot(data=hourly, x='hour', y='usage_min', marker='o')\n",
    "plt.xlabel('Hour of Day'); plt.ylabel('Total Usage (minutes)'); plt.title('Hourly Screen Time (All Users)')\n",
    "plt.grid(alpha=0.3); plt.show()\n",
    "\n",
    "# 4) Top 5 apps globally\n",
    "top5_global = top_n_apps(df, n=5, person_id=None)\n",
    "display(top5_global)\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=top5_global, x='usage_min', y='event_name', palette='viridis')\n",
    "plt.xlabel('Usage (minutes)'); plt.title('Top 5 Most Used Apps (Global)'); plt.show()\n",
    "\n",
    "# 5) Top 5 per person (Plotly grid for first 6 persons)\n",
    "persons = sorted(df['person_id'].dropna().unique())[:6]\n",
    "import plotly.subplots as psub\n",
    "fig = psub.make_subplots(rows=2, cols=3, subplot_titles=[f'Person {p}' for p in persons])\n",
    "r=1;c=1\n",
    "for i,p in enumerate(persons):\n",
    "    top5 = top_n_apps(df, n=5, person_id=p).sort_values('usage_min', ascending=True)\n",
    "    fig.add_trace(go.Bar(x=top5['usage_min'], y=top5['event_name'], orientation='h', name=f'P{p}'), row=r, col=c)\n",
    "    c += 1\n",
    "    if c>3:\n",
    "        r += 1; c = 1\n",
    "\n",
    "fig.update_layout(height=700, width=1000, title_text='Top 5 Apps for Selected Persons (minutes)')\n",
    "fig.show()\n",
    "\n",
    "# 6) Hourly heatmap per person\n",
    "hourly_p = df.groupby(['person_id','hour'])['usage_sec'].sum().reset_index()\n",
    "heat = hourly_p.pivot(index='person_id', columns='hour', values='usage_sec').fillna(0)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(heat/60, cmap='viridis')  # convert to minutes for readability\n",
    "plt.title('Hourly Usage Heatmap (minutes)'); plt.xlabel('Hour'); plt.ylabel('Person ID')\n",
    "plt.show()\n",
    "\n",
    "# 7) Session behavior: sessions per day and avg session duration\n",
    "session_count = df.groupby(['person_id','date']).size().reset_index(name='sessions')\n",
    "avg_session = df.groupby('person_id')['usage_sec'].mean().reset_index(name='avg_session_sec')\n",
    "print('Sessions per person (sample):'); display(session_count.head())\n",
    "print('\\nAvg session duration (sec) sample:'); display(avg_session.head())\n",
    "\n",
    "# 8) Sleep detection\n",
    "sleep_df = detect_sleep_periods(df)\n",
    "display(sleep_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Save notebook file path confirmation ---\n",
    "nb_path = '/mnt/data/combined_final_fg_events_analysis.ipynb'\n",
    "print('Notebook saved earlier to', nb_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
